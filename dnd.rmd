---
title: AP Statistics Chapter 5 Assignment
subtitle: Dungeons & Dragons (5th Edition) Monster Armor Classes
author: Caleb Smith
output: pdf_document
urlcolor: blue
---

# About

*Dungeons & Dragons* is a popular role-playing tabletop game, within which players are often pitted in combat against a variety of monsters. The 5th Edition *Monster Manual* is the definitive guidebook to the monsters found in the game (it is officially published by the creators of D&D), and contains 761 such creatures. Each monster has a number of game statistics - one of which is the creature's *Armor Class*, which determines how difficult it is for a player to deal damage to the monster. In this report, I've gathered and analyzed the Armor Classes of each creature in the Monster Manual. 

# 1. Dataset

Below is the data set for each of the monsters in the *Monster Manual* - values are listed in alphabetical order by the monster's name.

```{r, set-options, echo=FALSE}
raw <- read.csv("data.csv", header=TRUE)
ac = new("list")
ac$AC = raw$AC[!raw$AC %in% boxplot.stats(raw$AC)$out]
options("scipen"=100)
options(width = 88)
print(ac$AC, max = 999, row.names=FALSE)
```

# 2. Data Source

I found the data online in the form of Markdown documents, one per monster, which can be found [here](https://github.com/karagenit/bestiary/tree/master/_posts). Pages were parsed for data with [this script](https://github.com/karagenit/dnd-ac/blob/master/script.rb), which got the data into a basic CSV format (both as a number of counts per AC and as the raw AC values, the latter of which I used for this document). I then used [this script](https://github.com/karagenit/dnd-stats/blob/master/colsplit.sh) to split the columns into rows and manually added the AC header. 

Results of the script can be found [on this Google Doc](https://docs.google.com/spreadsheets/d/1GczVGTTNPxHVgNRFSQclzjwKyO30wLdCg6uDStq-raQ/edit?usp=sharing), or in [this CSV file](https://github.com/karagenit/dnd-stats/blob/master/data.csv).

A little about this document: I was originally planning on using LaTeX with latexpdf to generate a nice PDF report. However, I recently learned about the R statisics language, and decided to format this document with RMarkdown (the source for this document can be found [here](https://github.com/karagenit/dnd-stats/blob/master/dnd.rmd)) and build it through RStudio (which uses a combination of pandoc + texlive).

Originally I had to split the data with [this script](https://github.com/karagenit/csv-split/blob/master/script.rb) and then tabulated it for LaTeX with [this](https://github.com/karagenit/csv-latex-table/blob/master/script.sh), but R makes it easy to import and manipulate the data straight from CSV files.

# 3. Data Distribution & Normality

```{r, echo=FALSE}
hist(ac$AC,
     main = "Histogram of Armor Classes",
     xlab = "Armor Class",
     xlim = c(5,25),
     col = "blue",
     breaks = 20)
```

```{r, fig.align='center', echo=FALSE}
boxplot(ac$AC,
        main="Boxplot of Armor Classes",
        xlab="",
        ylab="Monster Manual ACs",
        horizontal = TRUE)
```

&nbsp;

```{r, fig.align='center', echo=FALSE}
ac.lm = lm(ac$AC ~ 1,
           data=ac)
ac.stdres = rstandard(ac.lm)
qqnorm(ac.stdres,
       xlab="Theoretical Quantiles (Z-Scores)",
       ylab="Empirical Quantiles (Residuals)",
       cex=1)
qqline(ac.stdres)
```

The histogram demonstrates that the data is mostly symmetrical (as there is no obvious skew) and is unimodal. The box plot demonstrates the data's symmetry through how evenly the median, quartiles, & fences are placed - it also suggests normality based on the size of the IQR compared to the range. The NPP shows that the data is mostly normal, as all of the data points are clustered near the linear model line. 

# 4. Center & Spread

```{r,echo=FALSE}
mean = mean(ac$AC)
sd = sd(ac$AC)
count = length(ac$AC)
```

Mean:

$$\mu = \frac{\Sigma x}{n}\rightarrow\frac{`r mean * count`}{`r count`}\approx`r round(mean, 2)`$$

Standard Deviation:

$$\delta = \sqrt{\frac{\Sigma{(x - \mu)}^2}{n}}\approx`r round(sd, 2)`$$

# 5. Z-Score Computations (Low Number)

```{r, echo=FALSE}
x1 = 10
z1 = (x1 - mean) / sd
p1 = pnorm(z1, lower.tail = FALSE)
```

Numer: $$x = `r x1`$$

Z-Score: $$Z = \frac{x-\mu}{\delta}\rightarrow
\frac{10-`r round(mean, 2)`}{`r round(sd, 2)`}\approx`r round(z1, 2)`$$

Percent Above: $$P(`r round(z1, 2)`< Z) \approx `r round(p1, 3)` = `r round(p1 * 100, 1)`\%$$

&nbsp;

```{r, echo=FALSE, fig.align='center'}
normseq <- seq(-4, 4, length = 100) * sd + mean
norm <- dnorm(normseq, mean, sd)

plot(normseq, norm, type="n", xlab="Armor Classes", ylab="",
  main="Normal Distribution", axes=FALSE)

i <- normseq >= x1
lines(normseq, norm)
polygon(c(x1,normseq[i],999), c(0,norm[i],0), col="blue")

area <- pnorm(999, mean, sd) - pnorm(x1, mean, sd)
result <- paste("P (",x1,"< AC ) =",
   signif(area, digits=3))
mtext(result,3)
axis(1, at=seq(0, 30, 5), pos=0)
```

# 6. Z-Score Computations (High Number)

```{r, echo=FALSE}
x2 = 12
z2 = (x2 - mean) / sd
p2 = pnorm(z2) - pnorm(z1)
```

Number: $$x = `r x2`$$

Z-Score: $$Z = \frac{x-\mu}{\delta}\rightarrow\frac{`r x2`-`r round(mean,2)`}{`r round(sd, 2)`}\approx`r round(z2, 2)`$$

Percent Between 10 & 12:  
$$P(`r round(z1, 2)` < Z < `r round(z2, 2)`) = P(Z < `r round(z2, 2)`) - P(Z < `r round(z1, 2)`)$$
$$\approx`r round(pnorm(z2),3)`-`r round(pnorm(z1),3)`= `r round(p2, 3)` = `r round(p2 * 100, 1)`\%$$

&nbsp;

```{r, fig.align='center', echo=FALSE}
plot(normseq, norm, type="n", xlab="Armor Classes", ylab="",
  main="Normal Distribution", axes=FALSE)

i <- normseq >= x1 & normseq <= x2
lines(normseq, norm)
polygon(c(x1,normseq[i],x2), c(0,norm[i],0), col="blue")

area <- pnorm(x2, mean, sd) - pnorm(x1, mean, sd)
result <- paste("P (",x1,"< AC <",x2,") =",
   signif(area, digits=3))
mtext(result,3)
axis(1, at=seq(0, 30, 5), pos=0)
```

# 7. 20th Percentile

```{r, echo=FALSE}
p3 = 0.2
z3 = qnorm(p3)
x3 = z3 * sd + mean
```

$$P(Z < z) = `r p3`$$
$$z = `r round(z3, 2)`$$
$$x = z * \delta + \mu$$
$$x = `r round(x3, 1)`$$

# 8. Empirical Probabilities

```{r, echo=FALSE}
ep1 = sum(ac$AC >= x1) / count
ep2 = sum(ac$AC >= x1 & ac$AC <= x2) / count
ex = sort(ac$AC)[[count * p3]]
ez = (ex - mean) / sd
```

Empirical % of Points Above `r x1`: $$`r round(ep1*100, 1)`\%$$

Empirical % of Points From `r x1` to `r x2`: $$`r round(ep2*100, 1)`\%$$

Empirical `r p3*100`th Percentile Data Point: $$x = `r round(ex, 0)`$$

Empirical `r p3*100`th Percentile Z-Score: $$z = `r round(ez, 2)`$$